{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initial configuration\n",
        "====================="
      ],
      "metadata": {
        "id": "29k48dhFk40m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5u3hHfOpySg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Dario-Caf/EM-shower-simulator-with-NN\n",
        "!pip install -r EM-shower-simulator-with-NN/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L\n",
        "!lscpu |grep 'Model name'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy7V8EV8lC0n",
        "outputId": "2ac4c631-b7cf-4430-b075-875d005f56af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-57b00bb0-af15-cbbd-9819-2fc2d42277cd)\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EM-shower-simulator-with-NN\n",
        "%cd EM_shower_simulator\n",
        "%run debug.py\n",
        "%run train.py"
      ],
      "metadata": {
        "id": "FL4fPtv2Db9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and costants\n",
        "===================="
      ],
      "metadata": {
        "id": "rJ0j8imfoWgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.train import CheckpointManager as Manager\n",
        "from tensorflow.keras.layers import (Input,\n",
        "                                     Concatenate,\n",
        "                                     Embedding,\n",
        "                                     Dense,\n",
        "                                     BatchNormalization,\n",
        "                                     LeakyReLU,\n",
        "                                     Reshape,\n",
        "                                     Conv3DTranspose,\n",
        "                                     MaxPooling3D,\n",
        "                                     AveragePooling3D,\n",
        "                                     Conv3D,\n",
        "                                     Dropout,\n",
        "                                     Lambda,\n",
        "                                     ELU,\n",
        "                                     Flatten)\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from constants import default_list\n",
        "\n",
        "# Train import\n",
        "from dataset import logData, data_pull, debug_data_pull, debug_shower\n",
        "\n",
        "from unbiased_metrics import shower_depth_lateral_width\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\"\"\"Constant parameters of configuration and definition of global objects.\"\"\"\n",
        "\n",
        "# Configuration parameters\n",
        "N_PID = 3\n",
        "N_ENER = 30 + 1\n",
        "NOISE_DIM = 1024\n",
        "MBSTD_GROUP_SIZE = 8                                     #minibatch dimension\n",
        "ENERGY_NORM = 6.7404\n",
        "ENERGY_SCALE = 1000000.\n",
        "GEOMETRY = (12, 25, 25, 1)\n",
        "PARAM_EN = 0.01\n",
        "\n",
        "# Define logger and handler\n",
        "logMod = logging.getLogger(\"ModelsLogger\")\n",
        "\n",
        "# Create a random seed, to be used during the evaluation of the cGAN.\n",
        "tf.random.set_seed(3)\n",
        "num_examples = 6\n",
        "test_noise = [tf.random.normal([num_examples, NOISE_DIM]),\n",
        "              tf.random.uniform([num_examples, 1], minval= 0., maxval=N_ENER),\n",
        "              tf.random.uniform([num_examples, 1], minval= 0., maxval=N_PID)]\n",
        "\n",
        "# Define logger\n",
        "logGAN = logging.getLogger(\"CGANLogger\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "VERBOSE = True\n",
        "\n",
        "# Path list from this folder\n",
        "path_list = [os.path.join('..', path) for path in default_list]\n",
        "\n",
        "\n",
        "# Examples to show\n",
        "EXAMPLES = 5\n",
        "\n",
        "# Define logger and handler\n",
        "ch = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger = logging.getLogger(\"DEBUGLogger\")\n",
        "logger.addHandler(ch)\n",
        "logData.addHandler(ch)\n",
        "logMod.addHandler(ch)\n",
        "logGAN.addHandler(ch)"
      ],
      "metadata": {
        "id": "5ClAnNUmobRF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make models: tests\n",
        "=================="
      ],
      "metadata": {
        "id": "3A89Uj9Z1qKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Subroutins for the creation of the generator and discriminator models.\"\"\"\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\"\"\"General subroutines for the network.\"\"\"\n",
        "def compute_energy(in_images):\n",
        "    \"\"\"Compute energy deposited in detector.\"\"\"\n",
        "    in_images = tf.cast(in_images, tf.float32)\n",
        "    en_images = tf.math.multiply(in_images, ENERGY_NORM)\n",
        "    en_images = tf.math.pow(10., en_images)\n",
        "    en_images = tf.math.divide(en_images, ENERGY_SCALE)\n",
        "    en_images = tf.math.reduce_sum(en_images, axis=[1,2,3])\n",
        "    return en_images\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\"\"\"Subroutines for the generator network.\"\"\"\n",
        "\n",
        "def make_generator_model():\n",
        "    \"\"\"Define generator model:\n",
        "    Input 1) Random noise from which the network creates a vector of images;\n",
        "    Input 2) Energy label to be passed to the network;\n",
        "    Input 3) ParticleID label to be passed to the network.\n",
        "\n",
        "    Labels are given as scalars in input; then they are passed to an embedding\n",
        "    layer that creates a sort of lookup-table (vector[EMBED_DIM] of floats) that\n",
        "    categorizes the labels in N_CLASSES * classes.\n",
        "    \"\"\"\n",
        "    BASE = 8\n",
        "    FILTER = 32\n",
        "    EMBED_DIM = 30\n",
        "    KERNEL_L = (1, 8, 8)\n",
        "    KERNEL_S = (3, 6, 6)\n",
        "    n_nodes = BASE*BASE*BASE\n",
        "    image_shape = (BASE, BASE, BASE, -1)\n",
        "\n",
        "    # Input[i] -> input[i] + convolution * (KERNEL-1)\n",
        "    error = \"ERROR building the generator: shape different from geometry!\"\n",
        "\n",
        "    # Image generator input\n",
        "    in_lat = Input(shape=(NOISE_DIM,), name=\"latent_input\")\n",
        "    li_lat = Reshape(image_shape)(in_lat)\n",
        "\n",
        "    # Energy label input\n",
        "    en_label = Input(shape=(1,), name=\"energy_input\")\n",
        "    li_en = Dense(2*FILTER, activation=\"relu\")(en_label)\n",
        "    li_en = Dense(n_nodes, activation=\"relu\")(li_en)\n",
        "    li_en = Reshape(image_shape)(li_en)\n",
        "\n",
        "    # ParticleID label input\n",
        "    pid_label = Input(shape=(1,), name=\"particle_input\")\n",
        "    li_pid = Embedding(N_PID, EMBED_DIM)(pid_label)\n",
        "    li_pid = Dense(n_nodes, activation=\"relu\")(li_pid)\n",
        "    li_pid = Reshape(image_shape)(li_pid)\n",
        "\n",
        "    # Combine noise and particle ID\n",
        "    gen = Concatenate()([li_lat, li_pid])\n",
        "    logMod.info(gen.get_shape())\n",
        "\n",
        "    gen = Conv3DTranspose(3, KERNEL_S, padding=\"same\", use_bias=False)(gen)\n",
        "    logMod.info(gen.get_shape())\n",
        "    # gen = BatchNormalization()(gen)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "    # Combine image and energy\n",
        "    gen = Concatenate()([gen, li_en])\n",
        "    logMod.info(gen.get_shape())\n",
        "\n",
        "    gen = Conv3DTranspose(FILTER, KERNEL_L, use_bias=False)(gen)\n",
        "    logMod.info(gen.get_shape())\n",
        "    # gen = BatchNormalization()(gen)\n",
        "    gen = LeakyReLU(alpha=0.1)(gen)\n",
        "\n",
        "    gen = Conv3DTranspose(FILTER, KERNEL_S, use_bias=False)(gen)\n",
        "    logMod.info(gen.get_shape())\n",
        "    # gen = BatchNormalization()(gen)\n",
        "    gen = LeakyReLU(alpha=0.1)(gen)\n",
        "\n",
        "    output = Conv3DTranspose(1, KERNEL_S, activation=\"tanh\", use_bias=False,\n",
        "                                                              name=\"image\")(gen)\n",
        "    # output = ELU(name=\"filtered_image\")(output)\n",
        "\n",
        "    logMod.info(f\"Shape of the generator output: {output.get_shape()}\")\n",
        "    assert output.get_shape().as_list()==[None, *GEOMETRY], error\n",
        "\n",
        "    model = Model([in_lat, en_label, pid_label], output, name='generator')\n",
        "    return model\n",
        "\n",
        "def debug_generator(noise, verbose=False):\n",
        "    \"\"\"Uses the random seeds to generate fake samples and plots them.\"\"\"\n",
        "    if verbose :\n",
        "        logMod.setLevel(logging.DEBUG)\n",
        "        logMod.info('Logging level set on DEBUG.')\n",
        "    else:\n",
        "        logMod.setLevel(logging.WARNING)\n",
        "        logMod.info('Logging level set on WARNING.')\n",
        "    logMod.info(\"Start debugging the generator model.\")\n",
        "\n",
        "    generator = make_generator_model()\n",
        "    data_images = generator(noise, training=False)\n",
        "    logMod.info(f\"Shape of generated images: {data_images.shape}\")\n",
        "\n",
        "    energy = compute_energy(data_images)\n",
        "\n",
        "    k=0\n",
        "    plt.figure(\"Generated showers\", figsize=(20,10))\n",
        "    num_examples = data_images.shape[0]\n",
        "    for i in range(num_examples):\n",
        "        print(f\"{i+1})\\tPrimary particle={int(noise[2][i][0])}\"\n",
        "             +f\"\\tInitial energy ={noise[1][i][0]}\"\n",
        "             +f\"\\tGenerated energy ={energy[i]}\\n\")\n",
        "        for j in range(data_images.shape[1]):\n",
        "           k=k+1\n",
        "           plt.subplot(num_examples, data_images.shape[1], k)\n",
        "           plt.imshow(data_images[i,j,:,:,0])\n",
        "           plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    logMod.info(\"Debug of the generator model finished.\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\"\"\"Subroutines for the discriminator network.\"\"\"\n",
        "\n",
        "def minibatch_stddev_layer(discr, group_size=MBSTD_GROUP_SIZE):\n",
        "    \"\"\"Minibatch discrimination layer is important to avoid mode collapse.\n",
        "    Once it is wrapped with a Lambda Keras layer it returns an additional filter\n",
        "    node with information about the statistical distribution of the group_size,\n",
        "    allowing the discriminator to recognize when the generator strarts to\n",
        "    replicate the same kind of event multiple times.\n",
        "\n",
        "    Inspired by\n",
        "    https://github.com/tkarras/progressive_growing_of_gans/blob/master/networks.py\n",
        "    \"\"\"\n",
        "    with tf.compat.v1.variable_scope('MinibatchStddev'):\n",
        "        # Input 0 dimension must be divisible by (or smaller than) group_size.\n",
        "        group_size = tf.minimum(group_size, tf.shape(discr)[0])\n",
        "        # Input shape.\n",
        "        shape = discr.shape\n",
        "        # Split minibatch into M groups of size G.\n",
        "        minib = tf.reshape(discr, [group_size, -1, shape[1], shape[2], shape[3], shape[4]])\n",
        "        # Cast to FP32.\n",
        "        minib = tf.cast(minib, tf.float32)\n",
        "        # Calculate the std deviation for each pixel over minibatch\n",
        "        minib = tf.math.reduce_std(minib + 1E-6, axis=0)\n",
        "        # Take average over fmaps and pixels.\n",
        "        minib = tf.reduce_mean(minib, axis=[2,3,4], keepdims=True)\n",
        "        # Cast back to original data type.\n",
        "        minib = tf.cast(minib, discr.dtype)\n",
        "        # New tensor by replicating input multiples times.\n",
        "        minib = tf.tile(minib, [group_size, 1 , shape[2], shape[3], 1])\n",
        "        # Append as new fmap.\n",
        "        return tf.concat([discr, minib], axis=-1)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    \"\"\"Define discriminator model:\n",
        "    Input 1) Vector of images associated to the given labels;\n",
        "    Input 2) Energy label to be passed to the network;\n",
        "    Input 3) ParticleID label to be passed to the network.\n",
        "\n",
        "    Labels are given as scalars in input; then they are passed to an embedding\n",
        "    layer that creates a sort of lookup-table (vector[EMBED_DIM] of floats) that\n",
        "    categorizes the labels in N_CLASSES * classes.\n",
        "    \"\"\"\n",
        "    N_FILTER = 32\n",
        "    KERNEL = (3, 6, 6)\n",
        "\n",
        "    # padding=\"same\" add a 0 to borders, \"valid\" use only available data !\n",
        "    # Output of convolution = (input + 2padding - kernel) / strides + 1 !\n",
        "    # Here we use padding default = \"valid\" (=0 above) and strides = 1 !\n",
        "    # GEOMETRY[i] -> GEOMETRY[i] - n_convolution * (KERNEL[i] - 1) > 0 !\n",
        "    error = \"ERROR building the discriminator: smaller KERNEL is required!\"\n",
        "\n",
        "    # Image input\n",
        "    in_image = Input(shape=GEOMETRY, name=\"input_image\")\n",
        "\n",
        "    discr = Conv3D(N_FILTER, KERNEL, use_bias=False)(in_image)\n",
        "    logMod.info(discr.get_shape())\n",
        "    discr = LeakyReLU(alpha=0.2)(discr)\n",
        "    discr = Dropout(0.2)(discr)\n",
        "\n",
        "    discr = AveragePooling3D(pool_size=(1,2,2), padding=\"valid\")(discr)\n",
        "\n",
        "    minibatch = Lambda(minibatch_stddev_layer, name=\"minibatch\")(discr)\n",
        "    logMod.info(f\"Minibatch shape: {discr.get_shape()}\")\n",
        "\n",
        "    discr = Conv3D(2*N_FILTER, KERNEL, use_bias=False)(minibatch)\n",
        "    logMod.info(discr.get_shape())\n",
        "    discr = LeakyReLU(alpha=0.2)(discr)\n",
        "    discr = Dropout(0.2)(discr)\n",
        "\n",
        "    discr = MaxPooling3D(pool_size=(2,2,2), padding=\"valid\")(discr)\n",
        "\n",
        "    logMod.info(discr.get_shape())\n",
        "    discr = Flatten()(discr)\n",
        "\n",
        "    discr_conv = Dense(2*N_FILTER, activation=\"relu\")(discr)\n",
        "    discr_conv = Dense(2*N_FILTER, activation=\"relu\")(discr_conv)\n",
        "    output_conv = Dense(1, activation=\"sigmoid\", name=\"decision\")(discr_conv)\n",
        "\n",
        "    discr_en = Dense(2*N_FILTER, activation=\"relu\")(discr)\n",
        "    discr_en = Dense(2*N_FILTER, activation=\"relu\")(discr_en)\n",
        "    output_en = Dense(1, activation=\"relu\", name=\"energy_label\")(discr_en)\n",
        "\n",
        "    discr_id = Dense(2*N_FILTER, activation=\"relu\")(discr)\n",
        "    discr_id = Dense(2*N_FILTER, activation=\"sigmoid\")(discr_id)\n",
        "    output_id = Dense(1, activation=\"sigmoid\", name=\"particle_label\")(discr_id)\n",
        "\n",
        "    output = [output_conv, output_en, output_id]\n",
        "    model = Model(in_image, output, name='discriminator')\n",
        "    return model\n",
        "\n",
        "def debug_discriminator(data, verbose=False):\n",
        "    \"\"\"Uses images from the sample to test discriminator model.\"\"\"\n",
        "    if verbose :\n",
        "        logMod.setLevel(logging.DEBUG)\n",
        "        logMod.info('Logging level set on DEBUG.')\n",
        "    else:\n",
        "        logMod.setLevel(logging.WARNING)\n",
        "        logMod.info('Logging level set on WARNING.')\n",
        "    logMod.info(\"Start debugging discriminator model.\")\n",
        "\n",
        "    discriminator = make_discriminator_model()\n",
        "    decision = discriminator(data)\n",
        "    logMod.info(f\"\\nDecision per raw:\\n {decision[0]}\")\n",
        "    logMod.info(\"Debug of the discriminator model finished.\")\n"
      ],
      "metadata": {
        "id": "-s24kngpoA2E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class CGAN: tests\n",
        "================="
      ],
      "metadata": {
        "id": "4rpB4Bwd2RWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Conditional GAN Class and structure \"\"\"\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def shower_depth_width(showers_vector):\n",
        "    \"\"\"Compute shower mean depth and std;\n",
        "       Compute shower mean lateral width among layers and std.\n",
        "    \"\"\"\n",
        "    shape = showers_vector.shape\n",
        "\n",
        "    layer_num= tf.constant([[x for x in range(shape[1])]])\n",
        "    layer_num= tf.cast(tf.tile(layer_num, [shape[0],1] ), tf.float32)\n",
        "    pixel_num= tf.constant([[[[x for x in range(-shape[2]//2+1, shape[2]//2+1)]\n",
        "                            for y in range(-shape[2]//2+1, shape[2]//2+1)]\n",
        "                            for l in range(shape[1]) ]])\n",
        "    pixel_num= tf.cast(tf.tile(\n",
        "                        pixel_num, [shape[0],1,1,1] ), tf.float32)\n",
        "    pixel_num= tf.reshape(pixel_num, shape)\n",
        "\n",
        "    pixel_en = tf.math.multiply(showers_vector, ENERGY_NORM)\n",
        "    pixel_en = tf.math.pow(10., pixel_en)\n",
        "    pixel_en = tf.math.divide(pixel_en, ENERGY_SCALE)\n",
        "\n",
        "    layers_en = tf.math.reduce_sum(pixel_en, axis=[2,3,4])\n",
        "    total_en  = tf.math.reduce_sum(layers_en, axis=1)\n",
        "\n",
        "    layers_scalar_prod_en   = tf.math.multiply(layers_en, layer_num)\n",
        "    depth_weighted_total_en = tf.math.reduce_sum(layers_scalar_prod_en, axis=1)\n",
        "\n",
        "    # shower depth\n",
        "    shower_depth = tf.math.divide(depth_weighted_total_en,total_en)\n",
        "    depth_mean = tf.math.reduce_mean(shower_depth, axis = 0)\n",
        "    depth_std  = tf.math.reduce_std(shower_depth, axis=0)\n",
        "\n",
        "    x = tf.math.multiply(pixel_en,pixel_num)\n",
        "    x = tf.math.reduce_sum(x, axis=[2,3,4])\n",
        "\n",
        "    x2 = tf.math.multiply(pixel_en, pixel_num**2)\n",
        "    x2 = tf.math.reduce_sum(x2, axis=[2,3,4])\n",
        "\n",
        "    # shower lateral width\n",
        "    lateral_width  = tf.math.sqrt(tf.math.abs(x2/layers_en - (x/layers_en)**2))\n",
        "    width_mean = tf.math.reduce_mean(lateral_width, axis=[0,1])\n",
        "    width_std  = tf.math.reduce_std(lateral_width, axis=[0,1])\n",
        "\n",
        "    metrics = [depth_mean, depth_std, width_mean, width_std]\n",
        "    return metrics\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "class ConditionalGAN(tf.keras.Model):\n",
        "    \"\"\"Class for a conditional GAN.\n",
        "    It inherits keras.Model properties and functions.\n",
        "    \"\"\"\n",
        "    def __init__(self, gener, discr, learning_rate=2e-5):\n",
        "        \"\"\"Constructor.\n",
        "        Inputs:\n",
        "        gener = generator network;\n",
        "        discr = discriminator network;\n",
        "        learning_rate = starting poor learning rate.\n",
        "        \"\"\"\n",
        "        super(ConditionalGAN, self).__init__()\n",
        "        self.generator = gener\n",
        "        self.discriminator = discr\n",
        "        self.history = {}\n",
        "        self.logs = {}\n",
        "\n",
        "        # Metrics\n",
        "        self.gener_loss_tracker = Mean(name=\"gener_loss\")\n",
        "        self.discr_loss_tracker = Mean(name=\"discr_loss\")\n",
        "        self.energ_loss_tracker = Mean(name=\"energy_loss\")\n",
        "        self.parID_loss_tracker = Mean(name=\"particle_loss\")\n",
        "        self.computed_e_tracker = Mean(name=\"computed_loss\")\n",
        "\n",
        "        # Unbiased metrics\n",
        "        self.mean_depth_tracker = Mean(name=\"mean_depth\")\n",
        "        self.std_depth_tracker  = Mean(name=\"std_depth\")\n",
        "        self.mean_lateral_tracker = Mean(name=\"mean_width\")\n",
        "        self.std_lateral_tracker  = Mean(name=\"std_width\")\n",
        "\n",
        "        # Optimizers\n",
        "        self.generator_optimizer = Adam(learning_rate * 10)\n",
        "        self.discriminator_optimizer = Adam(learning_rate)\n",
        "\n",
        "        # Manager to save rusults from training in form of checkpoints\n",
        "        self.checkpoint = tf.train.Checkpoint(\n",
        "                           generator=self.generator,\n",
        "                           discriminator=self.discriminator,\n",
        "                           generator_optimizer=self.generator_optimizer,\n",
        "                           discriminator_optimizer=self.discriminator_optimizer)\n",
        "\n",
        "        self.manager = Manager(self.checkpoint, './checkpoints', max_to_keep=5)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        \"\"\"Metrics of the cGAN network.\"\"\"\n",
        "        return [self.gener_loss_tracker,\n",
        "                self.discr_loss_tracker,\n",
        "                self.energ_loss_tracker,\n",
        "                self.parID_loss_tracker,\n",
        "                self.computed_e_tracker,\n",
        "                self.mean_depth_tracker,\n",
        "                self.std_depth_tracker,\n",
        "                self.mean_lateral_tracker,\n",
        "                self.std_lateral_tracker]\n",
        "\n",
        "    def update_metrics(self, args):\n",
        "        \"\"\"Update metrics and logs preventing NaN propagation.\"\"\"\n",
        "        for metric, arg in zip(self.metrics, args):\n",
        "            key = metric.name\n",
        "            if tf.math.is_nan(arg):\n",
        "                 raise AssertionError(f\"\\nERROR IN {key}: NAN VALUE\")\n",
        "            metric.update_state(arg)\n",
        "            self.logs[key] = metric.result().numpy()\n",
        "\n",
        "    def compile(self):\n",
        "        \"\"\"Compile method of the cGAN network.\n",
        "        Quite useless in this case because the training set up has been done in\n",
        "        the constructor of the class. It associate to the new abstract model an\n",
        "        optimizer attribute 'rmsprop', and loss, metrics=None.\n",
        "        \"\"\"\n",
        "        super(ConditionalGAN, self).compile()\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Summary method of the cGAN network.\"\"\"\n",
        "        print(\"\\nPrinting conditional GAN summary to file.\\n\")\n",
        "        save_path = Path('model_plot').resolve()\n",
        "        if not os.path.isdir(save_path):\n",
        "           os.makedirs(save_path)\n",
        "        file_name = \"cgan-summary.txt\"\n",
        "        path = os.path.join(save_path, file_name)\n",
        "        with open(path, 'w') as file:\n",
        "           file.write('\\nConditional GAN summary\\n\\n')\n",
        "           self.generator.summary(print_fn=lambda x: file.write(x + '\\n'))\n",
        "           file.write('\\n\\n')\n",
        "           self.discriminator.summary(print_fn=lambda x: file.write(x + '\\n'))\n",
        "           file.write('\\n\\n')\n",
        "\n",
        "    def plot_model(self):\n",
        "        \"\"\"Plot_model method of the cGAN network.\"\"\"\n",
        "        print(\"\\nPlotting and saving conditional GAN scheme.\\n\")\n",
        "        save_path = Path('model_plot').resolve()\n",
        "        if not os.path.isdir(save_path):\n",
        "           os.makedirs(save_path)\n",
        "\n",
        "        fig = plt.figure(\"Model scheme\", figsize=(20,10))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Generator\")\n",
        "        file_name = \"cgan-generator.png\"\n",
        "        path = os.path.join(save_path, file_name)\n",
        "        plot_model(self.generator, to_file=path, show_shapes=True)\n",
        "        plt.imshow(imread(path))\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Discriminator\")\n",
        "        file_name = \"cgan-discriminator.png\"\n",
        "        path = os.path.join(save_path, file_name)\n",
        "        plot_model(self.discriminator, to_file=path, show_shapes=True)\n",
        "        plt.imshow(imread(path))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        file_name = \"cgan-scheme.png\"\n",
        "        path = os.path.join(save_path, file_name)\n",
        "        fig.savefig(os.path.join(save_path, file_name))\n",
        "        plt.close()\n",
        "\n",
        "    def generate_noise(self, num_examples=num_examples):\n",
        "        \"\"\"Generate a set of num_examples noise inputs for the generator.\"\"\"\n",
        "        return [tf.random.normal([num_examples, NOISE_DIM]),\n",
        "                tf.random.uniform([num_examples, 1], minval= 0., maxval=N_ENER),\n",
        "                tf.random.uniform([num_examples, 1], minval= 0., maxval=N_PID)]\n",
        "\n",
        "    @tf.function\n",
        "    def compute_energy(self, in_images):\n",
        "        \"\"\"Compute energy deposited into the detector.\"\"\"\n",
        "        in_images = tf.cast(in_images, tf.float32)\n",
        "        en_images = tf.math.multiply(in_images, ENERGY_NORM)\n",
        "        en_images = tf.math.pow(10., en_images)\n",
        "        en_images = tf.math.divide(en_images, ENERGY_SCALE)\n",
        "        en_images = tf.math.reduce_sum(en_images, axis=[1,2,3])\n",
        "        return en_images\n",
        "\n",
        "    def evaluate(self, num_examples=num_examples):\n",
        "        \"\"\"Restore the last checkpoint and return the models.\"\"\"\n",
        "        if self.manager.latest_checkpoint:\n",
        "            latest_check = self.manager.latest_checkpoint\n",
        "            try:\n",
        "               self.checkpoint.restore(latest_check).expect_partial()\n",
        "            except:\n",
        "               raise Exception(\"Invalid checkpoint.\")\n",
        "            print(f\"Restored from {latest_check}\")\n",
        "            return self.generator, self.discriminator\n",
        "        else:\n",
        "            raise Exception(\"No checkpoint found.\")\n",
        "\n",
        "    def generate_and_save_images(self, noise, epoch=0):\n",
        "        \"\"\"Use the current status of the NN to generate images from the noise,\n",
        "        plot, evaluate and save them.\n",
        "        Inputs:\n",
        "        noise = noise with the generator input shape.\n",
        "        \"\"\"\n",
        "        # 1 - Generate images\n",
        "        predictions = self.generator(noise, training=False)\n",
        "        decisions = self.discriminator(predictions, training=False)\n",
        "        logGAN.info(f\"Shape of generated images: {predictions.shape}\")\n",
        "        energies = self.compute_energy(predictions)\n",
        "\n",
        "        # 2 - Plot the generated images\n",
        "        k = 0\n",
        "        num_examples = predictions.shape[0]\n",
        "        fig = plt.figure(\"Generated showers\", figsize=(20,10))\n",
        "        for i in range(num_examples):\n",
        "            print(f\"Example {i+1}\\t\"\n",
        "                 +f\"Primary particle = {int(noise[2][i][0])}\\t\"\n",
        "                 +f\"Predicted particle = {decisions[2][i][0]}\\n\"\n",
        "                 +f\"Initial energy = {noise[1][i][0]}\\t\"\n",
        "                 +f\"Generated energy = {energies[i][0]}\\t\"\n",
        "                 +f\"Predicted energy = {decisions[1][i][0]}\\t\"\n",
        "                 +f\"Decision = {decisions[0][i][0]}\\n\")\n",
        "            for j in range(predictions.shape[1]):\n",
        "                k=k+1\n",
        "                plt.subplot(num_examples, predictions.shape[1], k)\n",
        "                plt.imshow(predictions[i,j,:,:,0])\n",
        "                plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # 3 - Save the generated images\n",
        "        save_path = Path('model_results').resolve()\n",
        "        file_name = f\"image_at_epoch_{epoch}.png\"\n",
        "        if not os.path.isdir(save_path):\n",
        "           os.makedirs(save_path)\n",
        "        fig.savefig(os.path.join(save_path, file_name))\n",
        "\n",
        "    def scheduler(self, epoch, logs, wake_up):\n",
        "        \"\"\"Decrease the learning_rate:\n",
        "        Starting from epoch wake_up, the scheduler boosts the generator or\n",
        "        discriminator learning rate depending on which is doing better. The\n",
        "        comparison is made looking at the losses stored in logs.\n",
        "        \"\"\"\n",
        "        if (epoch > wake_up):\n",
        "           decrease = 0.999\n",
        "           gener_lr = self.generator_optimizer.lr.numpy()\n",
        "           discr_lr = self.discriminator_optimizer.lr.numpy()\n",
        "           self.generator_optimizer.lr = gener_lr * decrease\n",
        "           self.discriminator_optimizer.lr = discr_lr * decrease\n",
        "           logGAN.info(f\"Gener learning rate setted to {gener_lr * decrease}.\")\n",
        "           logGAN.info(f\"Discr learning rate setted to {discr_lr * decrease}.\")\n",
        "\n",
        "    def train_step(self, dataset):\n",
        "        \"\"\"Train step of the cGAN.\n",
        "        Inputs:\n",
        "        dataset = combined images  and labels upon which the network trained.\n",
        "\n",
        "        Description:\n",
        "        1) Create a noise to feed into the model for the images generation;\n",
        "        2) Generate images and calculate losses using real images and labels;\n",
        "        3) Calculate gradients using loss values and model variables;\n",
        "        4) Process Gradients and Run the Optimizer.\n",
        "        \"\"\"\n",
        "        mean_squared = MeanSquaredError()\n",
        "        cross_entropy = BinaryCrossentropy()\n",
        "\n",
        "        real_images, en_labels, pid_labels = dataset\n",
        "        noise = self.generate_noise(num_examples=real_images.shape[0])[0]\n",
        "\n",
        "        # GradientTape method records operations for automatic differentiation.\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # Compute real and fake outputs\n",
        "            generator_input = [noise, en_labels, pid_labels]\n",
        "            generated_images = self.generator(generator_input, training=True)\n",
        "\n",
        "            real_output = self.discriminator(real_images, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            # Compute GAN loss on decisions\n",
        "            ones = tf.ones_like(real_output[0])\n",
        "            zero = tf.zeros_like(fake_output[0])\n",
        "            real_loss = cross_entropy(ones, real_output[0])\n",
        "            fake_loss = cross_entropy(zero, fake_output[0])\n",
        "\n",
        "            gener_loss = cross_entropy(ones, fake_output[0])\n",
        "            discr_loss = real_loss + fake_loss\n",
        "\n",
        "            # Generated and computed energies\n",
        "            energies = self.compute_energy(generated_images)\n",
        "            computed_e = mean_squared(en_labels, energies)\n",
        "\n",
        "            # Compute auxiliary energy and particle losses\n",
        "            fake_energ = mean_squared(en_labels, fake_output[1])  # or energies?\n",
        "            real_energ = mean_squared(en_labels, real_output[1])\n",
        "\n",
        "            parID = tf.math.abs(tf.math.add(pid_labels, -1))\n",
        "            fake_parID = cross_entropy(parID, fake_output[2])\n",
        "            real_parID = cross_entropy(parID, real_output[2])\n",
        "\n",
        "            aux_gener_loss = (fake_energ + computed_e) * PARAM_EN + fake_parID\n",
        "            aux_discr_loss = (real_energ) * PARAM_EN + real_parID\n",
        "\n",
        "            # Compute total losses\n",
        "            gener_total_loss = aux_gener_loss + gener_loss\n",
        "            discr_total_loss = aux_discr_loss + discr_loss\n",
        "\n",
        "        grad_generator = gen_tape.gradient(gener_total_loss,\n",
        "                                        self.generator.trainable_variables)\n",
        "        self.generator_optimizer.apply_gradients(zip(grad_generator,\n",
        "                                        self.generator.trainable_variables))\n",
        "\n",
        "        grad_discriminator = disc_tape.gradient(discr_total_loss,\n",
        "                                        self.discriminator.trainable_variables)\n",
        "        self.discriminator_optimizer.apply_gradients(zip(grad_discriminator,\n",
        "                                        self.discriminator.trainable_variables))\n",
        "\n",
        "        logs = [gener_loss, discr_loss, real_energ, real_parID, computed_e]\n",
        "        self.update_metrics(logs)\n",
        "        return logs\n",
        "\n",
        "    def train(self, dataset, epochs=1, batch=32, wake_up=100, verbose=1):\n",
        "        \"\"\"Define the training function of the cGAN.\n",
        "        Inputs:\n",
        "        dataset = combined real images vectors and labels;\n",
        "        epochs = number of epochs for the training;\n",
        "        batch = number of batch in which dataset must be split;\n",
        "        wake_up = epoch in which learning rates start to switch and decrease.\n",
        "\n",
        "        For each epoch:\n",
        "        1) For each batch of the dataset, run the custom \"train_step\" function;\n",
        "        2) Produce images;\n",
        "        3) Save the model every 5 epochs as a checkpoint;\n",
        "        4) Print out the completed epoch no. and the time spent;\n",
        "        5) Then generate a final image after the training is completed.\n",
        "        \"\"\"\n",
        "        if verbose :\n",
        "            logGAN.setLevel(logging.DEBUG)\n",
        "            logGAN.info('Logging level set on DEBUG.')\n",
        "        else:\n",
        "            logGAN.setLevel(logging.WARNING)\n",
        "            logGAN.info('Logging level set on WARNING.')\n",
        "        dataset = dataset.batch(batch, drop_remainder=True)\n",
        "\n",
        "        # Call checkpoint manager to load the state or restart from scratch\n",
        "        switch = input(\"Do you want to restore the last checkpoint? [y/N]\")\n",
        "        if switch=='y':\n",
        "           if self.manager.latest_checkpoint:\n",
        "              latest_check = self.manager.latest_checkpoint\n",
        "              try:\n",
        "                 self.checkpoint.restore(latest_check).expect_partial()\n",
        "                 print(f\"Restored from {latest_check}\")\n",
        "              except:\n",
        "                 print(\"Invalid checkpoint: init from scratch.\")\n",
        "           else:\n",
        "              print(\"No checkpoint found: initializing from scratch.\")\n",
        "        else:\n",
        "            print(\"Initializing from scratch.\")\n",
        "\n",
        "        # Start training operations\n",
        "        display.clear_output(wait=True)\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Running EPOCH = {epoch + 1}/{epochs}\")\n",
        "            progbar = Progbar(len(dataset), verbose=1)\n",
        "\n",
        "            # Start iterate on batches\n",
        "            start = time.time()\n",
        "            try:\n",
        "                for index, image_batch in enumerate(dataset):\n",
        "                    logs = self.train_step(image_batch)\n",
        "                    progbar.update(index, zip(self.logs.keys(), logs))\n",
        "            except AssertionError as error:\n",
        "                print(f\"\\nEpoch {epoch}, batch {index}: {error}\")\n",
        "                break\n",
        "            end = time.time() - start\n",
        "\n",
        "            # Unbiased metrics computation\n",
        "            noise = self.generate_noise(num_examples=batch)\n",
        "            fake_images = self.generator(noise)\n",
        "            unb_metr = shower_depth_width(fake_images)\n",
        "            # note the following is the only way to append list of ope.tensor\n",
        "            self.update_metrics([*logs, *unb_metr])\n",
        "\n",
        "            # Dispaly results and save images\n",
        "            display.clear_output(wait=True)\n",
        "            print(f\"EPOCH = {epoch + 1}/{epochs}\")\n",
        "            for log in self.logs:\n",
        "                print(f\"{log} = {self.logs[log]}\")\n",
        "            print (f\"Time for epoch {epoch + 1} = {end} sec.\\n\")\n",
        "            self.generate_and_save_images(test_noise, epoch + 1)\n",
        "\n",
        "            # Update history and call scheduler\n",
        "            for key, value in self.logs.items():\n",
        "                self.history.setdefault(key, []).append(value)\n",
        "            self.scheduler(epoch + 1, self.logs, wake_up=wake_up)\n",
        "\n",
        "            # Save checkpoint\n",
        "            if (epoch + 1) % 3 == 0:\n",
        "               save_path = self.manager.save()\n",
        "               print(f\"Saved checkpoint for epoch {epoch + 1}: {save_path}\")\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def fit(self, dataset, epochs=1, batch=32):\n",
        "        \"\"\"Wrap the default training function of the model.\"\"\"\n",
        "        dataset = dataset.batch(batch, drop_remainder=True)\n",
        "        return super(ConditionalGAN, self).fit(dataset, epochs=epochs)\n"
      ],
      "metadata": {
        "id": "g9X0wyUXoSQs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other debug sub\n",
        "==============="
      ],
      "metadata": {
        "id": "IpoJXizq2fpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Train the GAN with the Geant generated dataset and save the model \"\"\"\n",
        "\n",
        "def global_metrics_real_data():\n",
        "    train_data = debug_data_pull(path_list, 10000)\n",
        "    train_images = train_data[0]\n",
        "    metrics = shower_depth_lateral_width(train_images)\n",
        "    for el in metrics:\n",
        "        print(f\"{el} = {metrics[el]}\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def debug(path_list, num_examples=EXAMPLES, verbose=False):\n",
        "    \"\"\"Debug subroutines for the training of the cGAN with dataset in path.\"\"\"\n",
        "    if verbose :\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "        logger.info('Logging level set on DEBUG.')\n",
        "    else:\n",
        "        logger.setLevel(logging.WARNING)\n",
        "        logger.info('Logging level set on WARNING.')\n",
        "\n",
        "    try:\n",
        "        train_data = debug_data_pull(path_list, num_examples, verbose=verbose)\n",
        "    except AssertionError as error:\n",
        "        print(f\"An error occurred while loading the dataset: \\n{error}\")\n",
        "        sys.exit()\n",
        "\n",
        "    #Execute debug subroutines\n",
        "    train_images = train_data[0]\n",
        "    debug_shower(train_images, verbose)\n",
        "    debug_generator(test_noise, verbose=verbose)\n",
        "    debug_discriminator(train_images, verbose)\n",
        "\n",
        "def debug_cgan(gan, path_list, num_examples=EXAMPLES):\n",
        "    \"\"\"Debug of the cGAN methods.\"\"\"\n",
        "    logger.info(\"Testing the cGAN methods on noise and real samples.\")\n",
        "    noise = gan.generate_noise(num_examples)\n",
        "    gan.generate_and_save_images(noise)\n",
        "\n",
        "    gener, discr = gan.evaluate()\n",
        "\n",
        "    # Fake showers\n",
        "    predictions = gener(noise, training=False)\n",
        "    decisions = discr(predictions, training=False)\n",
        "    energies = compute_energy(predictions)\n",
        "\n",
        "    k = 0\n",
        "    num_examples = predictions.shape[0]\n",
        "    side = predictions.shape[1]\n",
        "    fig = plt.figure(\"Fake generated showers\", figsize=(20,10))\n",
        "    for i in range(num_examples):\n",
        "        print(f\"Example {i+1}\\n\"\n",
        "             +f\"Primary particle = {int(noise[2][i][0])}\\t\"\n",
        "             +f\"Predicted particle = {decisions[2][i][0]}\\n\"\n",
        "             +f\"Initial energy = {noise[1][i][0]}\\t\"\n",
        "             +f\"Generated energy = {energies[i][0]}\\t\"\n",
        "             +f\"Predicted energy = {decisions[1][i][0]}\\t\"\n",
        "             +f\"Decision = {decisions[0][i][0]}\\n\\n\")\n",
        "        for j in range(side):\n",
        "            k=k+1\n",
        "            plt.subplot(num_examples, side, k)\n",
        "            plt.imshow(predictions[i,j,:,:,0])\n",
        "            plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # True showers\n",
        "    predictions = debug_data_pull(path_list, num_examples)\n",
        "    images = predictions[0]\n",
        "    decisions = discr(images, training=False)\n",
        "    energies = compute_energy(images)\n",
        "\n",
        "    k = 0\n",
        "    fig = plt.figure(\"Real generated showers\", figsize=(20,10))\n",
        "    for i in range(num_examples):\n",
        "        print(f\"Example {i+1}\\n\"\n",
        "             +f\"Primary particle = {int(noise[2][i][0])}\\t\"\n",
        "             +f\"Predicted particle = {decisions[2][i][0]}\\n\"\n",
        "             +f\"Initial energy = {noise[1][i][0]}\\t\"\n",
        "             +f\"Generated energy = {energies[i][0]}\\t\"\n",
        "             +f\"Predicted energy = {decisions[1][i][0]}\\t\"\n",
        "             +f\"Decision = {decisions[0][i][0]}\\n\\n\")\n",
        "        for j in range(side):\n",
        "            k=k+1\n",
        "            plt.subplot(num_examples, side, k)\n",
        "            plt.imshow(images[i,j,:,:,0])\n",
        "            plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    logger.info(\"Debug of the cGAN methods finished.\")\n"
      ],
      "metadata": {
        "id": "l9uwDbGU2ibn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEBUG & TRAIN\n",
        "============="
      ],
      "metadata": {
        "id": "_-VcOEhU-6H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug(path_list, verbose=VERBOSE)\n",
        "generator = make_generator_model()\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "cond_gan = ConditionalGAN(generator, discriminator)\n",
        "logger.info(\"The cGAN model has been built correctly.\")\n",
        "\n",
        "cond_gan.summary()\n",
        "cond_gan.plot_model()\n",
        "logger.info(\"The cGAN model has been plotted correctly.\")\n",
        "\n",
        "try:\n",
        "    debug_cgan(cond_gan, path_list)\n",
        "except error:\n",
        "    print(error)\n",
        "\n",
        "logger.info(\"The work is done.\")\n",
        "logger.handlers.clear()"
      ],
      "metadata": {
        "id": "mYC6_2V17EVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Creation and training of the conditional GAN.\"\"\"\n",
        "if VERBOSE :\n",
        "   logger.setLevel(logging.DEBUG)\n",
        "   logger.info('Logging level set on DEBUG.')\n",
        "else:\n",
        "   logger.setLevel(logging.WARNING)\n",
        "   logger.info('Logging level set on WARNING.')\n",
        "\n",
        "logger.info(\"Start building operations.\")\n",
        "train_dataset = data_pull(path_list)\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "cond_gan = ConditionalGAN(generator, discriminator)\n",
        "logger.info(\"The cGAN model has been built correctly.\")\n",
        "\n",
        "global_metrics_real_data()\n",
        "history = cond_gan.train(train_dataset, epochs=30, batch=64, wake_up=70)\n",
        "np.save(os.path.join(\"model_results\",\"history.npy\"), history)\n",
        "\n",
        "# only to remember how to load the dictionary:\n",
        "hist = np.load(os.path.join(\"model_results\",\"history.npy\"), allow_pickle=True)\n",
        "plt.figure(\"Evolution of losses per epochs\")\n",
        "for key in history:\n",
        "    plt.plot(history[key], label=key)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "logger.info(\"The cGAN model has been trained correctly.\")\n",
        "\n",
        "logger.info(\"The work is done.\")\n",
        "logger.handlers.clear()"
      ],
      "metadata": {
        "id": "crNyAF-Q584d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = np.load(os.path.join(\"model_results\",\"history.npy\"), allow_pickle=True)\n",
        "hist = hist.item() # necessary because numpy create a structured dictionary\n",
        "print(hist)\n",
        "plt.figure(\"Evolution of losses per epochs\")\n",
        "for key in hist:\n",
        "    plt.plot(hist[key], label=key)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MtJI-Zj8sbbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "8a3e1d35-d816-4b3a-b141-38d5021bd163"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gener_loss': [0.7252606, 0.78303105, 0.8003661, 0.7777354, 0.7610364, 0.7564101, 0.75286263, 0.75853515, 0.7648583], 'discr_loss': [0.9742902, 0.8347351, 0.80369586, 0.8562971, 0.91041154, 0.93259865, 0.9478591, 0.94697374, 0.94011503], 'energy_loss': [310.45935, 310.65887, 310.65005, 310.61633, 310.61417, 310.64304, 310.64304, 310.60706, 310.60266], 'particle_loss': [0.6920603, 0.683049, 0.6744925, 0.6677228, 0.6624761, 0.6579899, 0.65389574, 0.65015894, 0.6466889], 'computed_loss': [171.28337, 88.000916, 59.823406, 45.976994, 37.779438, 31.76376, 27.465616, 24.43375, 21.932096], 'mean_depth': [4.666972, 4.761089, 4.771623, 4.727152, 4.7227855, 4.7216697, 4.686349, 4.6900063, 4.6423554], 'std_depth': [0.3039991, 0.19292337, 0.3487409, 0.328963, 0.30052048, 0.31467995, 0.31368965, 0.29649624, 0.33351102], 'mean_width': [3.3942966, 3.9942417, 3.6519277, 3.7987218, 3.874646, 3.779237, 3.734157, 3.6604588, 3.6577623], 'std_width': [2.1299264, 2.611724, 2.6580184, 2.6466222, 2.7811673, 2.7691317, 2.7458065, 2.7148588, 2.7248383]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to git\n",
        "==========="
      ],
      "metadata": {
        "id": "RBNoCprKtBE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "J1Jmj9LotEgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .."
      ],
      "metadata": {
        "id": "WAVN2Madua4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"push from colab\""
      ],
      "metadata": {
        "id": "LlYcQITeucv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "id": "pvgN0HLyuiBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Debug and train cGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rJ0j8imfoWgI",
        "3A89Uj9Z1qKr",
        "4rpB4Bwd2RWK",
        "IpoJXizq2fpY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}